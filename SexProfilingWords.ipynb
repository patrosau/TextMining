{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import operator\n",
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "directory='/home/patrosau@alumno.upv.es/Descargas/hispatweets/'\n",
    "\n",
    "def getFileName(directory, country, userId):\n",
    "    return directory + country + '/' + user + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "def tokenizeTweet(tweet):\n",
    "\n",
    "    # eliminamos mencion de usuarios, quitamos las repeticiones de mas de 3 letras y pasamos a minusculas\n",
    "    tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True, preserve_case=False)\n",
    "    \n",
    "    return tokenizer.tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Diccionario por sexo de los ficheros de training\n",
    "sexdic = dict()\n",
    "with open(directory + 'training.txt') as trainingFile:\n",
    "    for line in trainingFile:\n",
    "        [user, country, sex] = line.split(':::')\n",
    "        file_Name = getFileName(directory, country, user)\n",
    "        \n",
    "        if (sex in sexdic):\n",
    "            sexdic[sex].append(file_Name)\n",
    "        else:\n",
    "            sexdic[sex] = list()\n",
    "            sexdic[sex].append(file_Name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calcula frecuencias de aparicion de palabras en los tweets de entrada, en este caso sin eliminar nada\n",
    "# para discriminar entre hombre y mujer vamos a tenerlo todo en cuenta\n",
    "def getFrequentWords(files):\n",
    "\n",
    "    sw_spanish = sw.words('spanish')\n",
    "    d = dict()\n",
    "\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            for line in f:\n",
    "                tokens = tokenizeTweet(json.loads(line)['text'])\n",
    "                for word in tokens:\n",
    "                    d[word] = d.get(word, 0) + 1\n",
    "\n",
    "    return sorted(d.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ver la frecuencia de palabras utilizadas por cada sexo\n",
    "frequentWordsPerSex = dict()\n",
    "for sex in sexdic:\n",
    "    frequentWordsPerSex[sex] = getFrequentWords(sexdic[sex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordUserByOtherSex(inWord, inSex):\n",
    "    for sex in frequentWordsPerSex:\n",
    "        if (sex != inSex):\n",
    "            for word in frequentWordsPerSex[sex][:500]:\n",
    "                if (word[0] == inWord ):\n",
    "                    return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# de las 500 palabras mas utilizadas de cada sexo ver cuales no aparecen en los otros sexos (tarda mucho)\n",
    "distinctWordsPerSex = dict()\n",
    "for sex in frequentWordsPerSex:\n",
    "    distinctWordsPerSex[sex] = list()\n",
    "    for word in frequentWordsPerSex[sex][:500]:\n",
    "        if (wordUserByOtherSex(word[0], sex) == 0):\n",
    "            distinctWordsPerSex[sex].append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bolsaPalabras = list()\n",
    "for sex in distinctWordsPerSex:\n",
    "    for word in distinctWordsPerSex[sex]:\n",
    "        bolsaPalabras.append(word)\n",
    "len(bolsaPalabras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def palabraIsUsed(palabra, uw):\n",
    "    for p in uw:\n",
    "        if p[0] == palabra:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeaturesList(fileName):\n",
    "    res = list()\n",
    "    palabrasUsadas = getFrequentWords(fileName)\n",
    "    for palabra in bolsaPalabras:\n",
    "            if palabraIsUsed(palabra,palabrasUsadas):\n",
    "                res.append(1)\n",
    "            else:\n",
    "                res.append(0)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getTrainingData(user, country):\n",
    "    listFiles = list()\n",
    "    listFiles.append(getFileName(directory, country, user))\n",
    "    userVector = getFeaturesList(listFiles)\n",
    "    return userVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(directory + 'sexwordstrainingdata.txt', 'w') as train:\n",
    "    with open(directory + 'training.txt') as trainingFile:\n",
    "        for line in trainingFile:\n",
    "            [user, country, sex] = line.split(':::')\n",
    "            train.write(user + ',')\n",
    "            userVector = getTrainingData(user, country)\n",
    "            for feature in userVector:\n",
    "                train.write(str(feature) + ',')\n",
    "            train.write(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(directory + 'sexwordstestdata.txt', 'w') as train:\n",
    "    with open(directory + 'test.txt') as trainingFile:\n",
    "        for line in trainingFile:\n",
    "            [user, country, sex] = line.split(':::')\n",
    "            train.write(user + ',')\n",
    "            userVector = getTrainingData(user, country)\n",
    "            for feature in userVector:\n",
    "                train.write(str(feature) + ',')\n",
    "            train.write(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge word features and counters features (sextrainingdata.txt and sexwordstrainingdata.txt)\n",
    "def mergeData(wordsFile, countersFile):\n",
    "    wordsDataPerUser = dict()\n",
    "    with open(directory + wordsFile) as file:\n",
    "            for line in file:\n",
    "                values = line.split(',')\n",
    "                if (values[0] != '\\n'):\n",
    "                    wordsDataPerUser[values[0]] = values[1:len(values) - 2];\n",
    "                    \n",
    "    with open(directory + countersFile) as countersFile:\n",
    "        for line in countersFile:\n",
    "            values = line.split(',')\n",
    "            if (values[0] != '\\n' ):\n",
    "                for v in values[1:len(values) - 2]:\n",
    "                    wordsDataPerUser[values[0]].append(v);\n",
    "    \n",
    "    return wordsDataPerUser\n",
    "                    \n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainingDataPerUser = mergeData('sexwordstrainingdata.txt', 'sextrainingdata.txt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(directory + 'sexmergetrainingdata.txt', 'w') as train:\n",
    "    with open(directory + 'training.txt') as trainingFile:\n",
    "        for line in trainingFile:\n",
    "            [user, country, sex] = line.split(':::')\n",
    "            train.write(user + ',')\n",
    "            userVector = trainingDataPerUser[user]\n",
    "            for feature in userVector:\n",
    "                train.write(str(feature) + ',')\n",
    "            train.write(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testDataPerUser = mergeData('sexwordstestdata.txt', 'sextestdata.txt');\n",
    "with open(directory + 'sexmergetestdata.txt', 'w') as train:\n",
    "    with open(directory + 'test.txt') as trainingFile:\n",
    "        for line in trainingFile:\n",
    "            [user, country, sex] = line.split(':::')\n",
    "            train.write(user + ',')\n",
    "            userVector = testDataPerUser[user]\n",
    "            for feature in userVector:\n",
    "                train.write(str(feature) + ',')\n",
    "            train.write(sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
